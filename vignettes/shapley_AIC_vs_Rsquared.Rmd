 ---
title: "shapley_AIC_vs_Rsquared"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{shapley_AIC_vs_Rsquared}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  cache    = TRUE,
  comment  = "#>"
)
```

```{r setup}
library(shapleyAIC)
library(dplyr)
library(ggplot2)
library(tidyr)
```

To start, let us see how the shapley values may be used to pick out "dud" variables from "good" variables in a multiple linear regression setup. We will call our good variables $X_1,X_2,X_3,X_4$ and we will call our "dud" variables $Z_1,Z_2,Z_3,Z_4$. Our true model will be $Y = \beta_0 + \beta_1X_1 +\beta_2X_2+ \beta_3X_3 + \beta_4X_4 + \varepsilon$ where $\varepsilon \sim \mathcal{N}(\mathbf{0},\sigma^2I_n)$. We then fit the linear model $Y = \beta_0 + \beta_1X_1 +\beta_2X_2+ \beta_3X_3 + \beta_4X_4 +\beta_5Z_1 + \beta_6Z_2 + \beta_7Z_3 + + \beta_8Z_4 + \varepsilon$ and calculate shapley values for the variables. We will simulate a large amount of data, then see how well the shapley values pick out the useful/not useful variables. For simplicity in this first examples, we will make $\beta_0=0$, $\beta_1=\beta_2=\beta_3=\beta_4=0$, and $\sigma^2=1$.  

## Shapley values in the "trivial" case

```{r}
#setup##########################################################################
set.seed(73186)
AICvectors <- list()
rsqvectors <- list()
nsim  <- 100
nsamp <- 50
beta_true <- c(1,1,1,1,0,0,0,0)

#simulation loop################################################################
#timing the simulation loop
start_time = Sys.time()

#for loop simulates the models and stores the shapley values
for(i in 1:nsim){
  #randomly generate explanatory covariates
  X1 <- rnorm(nsamp)
  X2 <- rnorm(nsamp)
  X3 <- rnorm(nsamp)
  X4 <- rnorm(nsamp)
  Z1 <- rnorm(nsamp)
  Z2 <- rnorm(nsamp)
  Z3 <- rnorm(nsamp)
  Z4 <- rnorm(nsamp)
  
  #put together into design matrix
  X <- cbind(X1,X2,X3,X4,Z1,Z2,Z3,Z4)
  
  #calculate Y 
  Y <- X%*%cbind(beta_true)+rnorm(nsamp)
  
  #calculate variables shapley values
  Yshap <- shapley(Y,X)
  AICvectors[[i]]<- Yshap$AIC_shapleys
  rsqvectors[[i]]<- Yshap$rsq_shapleys
}

#report time used by loop:
end_time = Sys.time()
cat("Time elapsed after ",nsim," simulations of sample size ",nsamp,":\n",
    end_time-start_time,"\n")

#post-simulation organizing#####################################################
#store shapley values into a data frame
AICshapleys <- matrix(unlist(AICvectors),nrow=nsim,byrow=TRUE)
colnames(AICshapleys) <- names(AICvectors[[1]])
AICshapleys <- as.data.frame(AICshapleys)
AICshapleys$scorefn <- rep("AIC",nsim)
rsqshapleys <- matrix(unlist(rsqvectors),nrow=nsim,byrow=TRUE)
colnames(rsqshapleys) <- names(rsqvectors[[1]])
rsqshapleys <- as.data.frame(rsqshapleys)
rsqshapleys$scorefn <- rep("R_Squared",nsim)
shapleys <- dplyr::full_join(AICshapleys,rsqshapleys,by = c("X1", "X2", "X3", 
                                                            "X4", "Z1", "Z2", 
                                                            "Z3", "Z4", 
                                                            "scorefn"))


#Plotting histograms of shapley values##########################################
#now we transform this data frame and plot a histogram of all the shapley values
shapleys%>%
  tidyr::pivot_longer(1:8,names_to = "variable",values_to = "shapley_value")%>%
  dplyr::mutate(var_useful = grepl("X",variable))%>%
  ggplot2::ggplot(aes(x=shapley_value,fill=var_useful))+
  ggplot2::geom_histogram(position = "dodge")+
  ggplot2::facet_wrap(~scorefn,scales="free")
```

We can also calculate the number of "false positives" in each model. We will define this false positive number to be the number of $Z$ variables which have Shapley Values higher than the lowest X variable Shapley Value. We can calculate this number for each simulated model and get summary statistics for it:

```{r}
#calculating false positive rates###############################################
#data frame for false positives
false_positives <- data.frame(
  AIC = rep(NA,nsim),
  r_squared = rep(NA,nsim)
)

#for loop for AIC false positives
for(i in 1:nsim){
  smallest_X <- min(AICshapleys[i,1:4])
  false_positives$AIC[i]<-sum(AICshapleys[i,5:8]>smallest_X)
}

#for loop for r-squared false positives
for(i in 1:nsim){
  smallest_X <- min(rsqshapleys[i,1:4])
  false_positives$r_squared[i]<-sum(rsqshapleys[i,5:8]>smallest_X)
}

#summarize these two false-positive rates
apply(false_positives,MARGIN = 2,FUN=summary)
```

We see that in this trivial case, the separation in the shapley values is high enough that there is a zero false-positive rate with this rng seed. Another metric that we may wish to calculate is the following ratio, which is meant to characterize the separation of the X Shapley Values and the Z Shapley Values:
\[
\rho = \frac{\min\{\varphi(X_i)\}-\max\{\varphi(Z_i)\}}{\max\{\varphi(X_i),\varphi(Z_j)\}-\min\{\varphi(X_i),\varphi(Z_j)\}}
\]
observe that this "separation ratio" takes values in $\rho\in(-1,1)$, with negative numbers indicating a false positive rate greater than 0. The larger the distance between the smallest $\varphi(X_i)$ and the largest $\varphi(Z_i)$, the greater the numerator becomes in absolute value. Assuming no false positives, if we let the distance between the set of $\{\varphi(X_i)\}$ and $\{\varphi(Z_i)\}$ get infinitely large, we get that this ratio approaches $1$. So, the better separated the two clouds of points are, the closer this ratio should be to 1. If the smallest shapley value is an $X$ value, and the largest shapley value is a $Z$ value, then this ratio is -1. Let's calculate it for the AIC and $R^2$ based shapley values and see how they compare:

```{r}
#Separation Ratios##############################################################
separation <- data.frame(
  AIC = rep(NA,nsim),
  r_squared = rep(NA,nsim)
)

#for loop for AIC false positives
for(i in 1:nsim){
  smallest_X <- min(AICshapleys[i,1:4])
  largest_Z  <- max(AICshapleys[i,5:8])
  smallest   <- min(AICshapleys[i,1:8])
  largest    <- max(AICshapleys[i,1:8])
  separation$AIC[i]<- (smallest_X-largest_Z)/(largest-smallest)
}

#for loop for r-squared false positives
for(i in 1:nsim){
  smallest_X <- min(rsqshapleys[i,1:4])
  largest_Z  <- max(rsqshapleys[i,5:8])
  smallest   <- min(rsqshapleys[i,1:8])
  largest    <- max(rsqshapleys[i,1:8])
  separation$r_squared [i]<- (smallest_X-largest_Z)/(largest-smallest)
}

#summarize these two false-positive rates
apply(separation,MARGIN = 2,FUN=summary)

#plot these separation ratios, along with a y=x reference line to see when 
#AIC shapley values achieve "Better separation"
plot(separation$r_squared,separation$AIC,
     xlab="R-Squared based separation",
     ylab="AIC based separation",
     main="Separation ratios using two shapley value scoring schemes")
abline(a=0,b=1,lty=2,col="red")
```

We see from these summary stats and this plot that in the trivial setting, the AIC based shapley values appear to be performing somewhat better than the R-Squared based Shapley Values. What happens if we decrease the effect size? We can repeat the above code using $\beta_1=\beta_2=\beta_3=\beta_4=\frac12$ to see how this effects the performance of both shapley value schemes:

```{r smaller effect trivial, echo=FALSE}
#setup##########################################################################
AICvectors <- list()
rsqvectors <- list()
nsim  <- 100
nsamp <- 50
beta_true <- (1/2)*c(1,1,1,1,0,0,0,0)

#simulation loop################################################################
#timing the simulation loop
start_time = Sys.time()

#for loop simulates the models and stores the shapley values
for(i in 1:nsim){
  #randomly generate explanatory covariates
  X1 <- rnorm(nsamp)
  X2 <- rnorm(nsamp)
  X3 <- rnorm(nsamp)
  X4 <- rnorm(nsamp)
  Z1 <- rnorm(nsamp)
  Z2 <- rnorm(nsamp)
  Z3 <- rnorm(nsamp)
  Z4 <- rnorm(nsamp)
  
  #put together into design matrix
  X <- cbind(X1,X2,X3,X4,Z1,Z2,Z3,Z4)
  
  #calculate Y 
  Y <- X%*%cbind(beta_true)+rnorm(nsamp)
  
  #calculate variables shapley values
  Yshap <- shapley(Y,X)
  AICvectors[[i]]<- Yshap$AIC_shapleys
  rsqvectors[[i]]<- Yshap$rsq_shapleys
}

#report time used by loop:
end_time = Sys.time()
cat("Time elapsed after ",nsim," simulations of sample size ",nsamp,":\n",
    end_time-start_time,"\n")

#post-simulation organizing#####################################################
#store shapley values into a data frame
AICshapleys <- matrix(unlist(AICvectors),nrow=nsim,byrow=TRUE)
colnames(AICshapleys) <- names(AICvectors[[1]])
AICshapleys <- as.data.frame(AICshapleys)
AICshapleys$scorefn <- rep("AIC",nsim)
rsqshapleys <- matrix(unlist(rsqvectors),nrow=nsim,byrow=TRUE)
colnames(rsqshapleys) <- names(rsqvectors[[1]])
rsqshapleys <- as.data.frame(rsqshapleys)
rsqshapleys$scorefn <- rep("R_Squared",nsim)
shapleys <- dplyr::full_join(AICshapleys,rsqshapleys,by = c("X1", "X2", "X3", 
                                                            "X4", "Z1", "Z2", 
                                                            "Z3", "Z4", 
                                                            "scorefn"))


#Plotting histograms of shapley values##########################################
#now we transform this data frame and plot a histogram of all the shapley values
shapleys%>%
  tidyr::pivot_longer(1:8,names_to = "variable",values_to = "shapley_value")%>%
  dplyr::mutate(var_useful = grepl("X",variable))%>%
  ggplot2::ggplot(aes(x=shapley_value,fill=var_useful))+
  ggplot2::geom_histogram(position = "dodge")+
  ggplot2::facet_wrap(~scorefn,scales="free")

#calculating false positive rates###############################################
#data frame for false positives
false_positives <- data.frame(
  AIC = rep(NA,nsim),
  r_squared = rep(NA,nsim)
)

#for loop for AIC false positives
for(i in 1:nsim){
  smallest_X <- min(AICshapleys[i,1:4])
  smallest_X
  
  false_positives$AIC[i]<-sum(AICshapleys[i,5:8]>smallest_X)
  
}

#for loop for r-squared false positives
for(i in 1:nsim){
  smallest_X <- min(rsqshapleys[i,1:4])
  false_positives$r_squared[i]<-sum(rsqshapleys[i,5:8]>smallest_X)
}

#summarize these two false-positive rates
cat("False Positive summary statistics\n")
apply(false_positives,MARGIN = 2,FUN=summary)

#Separation Ratios##############################################################
separation <- data.frame(
  AIC = rep(NA,nsim),
  r_squared = rep(NA,nsim)
)

#for loop for AIC false positives
for(i in 1:nsim){
  smallest_X <- min(AICshapleys[i,1:4])
  largest_Z  <- max(AICshapleys[i,5:8])
  smallest   <- min(AICshapleys[i,1:8])
  largest    <- max(AICshapleys[i,1:8])
  separation$AIC[i]<- (smallest_X-largest_Z)/(largest-smallest)
}

#for loop for r-squared false positives
for(i in 1:nsim){
  smallest_X <- min(rsqshapleys[i,1:4])
  largest_Z  <- max(rsqshapleys[i,5:8])
  smallest   <- min(rsqshapleys[i,1:8])
  largest    <- max(rsqshapleys[i,1:8])
  separation$r_squared [i]<- (smallest_X-largest_Z)/(largest-smallest)
}

#summarize these two false-positive rates
cat("Separation ratio summary statistics\n")
apply(separation,MARGIN = 2,FUN=summary)

#plot these separation ratios, along with a y=x reference line to see when 
#AIC shapley values achieve "Better separation"
plot(separation$r_squared,separation$AIC,
     xlab="R-Squared based separation",
     ylab="AIC based separation",
     main="Separation ratios using two shapley value scoring schemes")
abline(a=0,b=1,lty=2,col="red")
```

This time, the separation is not perfect. So, we can plot the false positives in a similar way to see if there are cases where one Shapley Value score scheme mis-identifies but the other does not. Points are jittered a small amount to compensate for overplotting:

```{r}
#plot false positives for both schemes
ggplot2::ggplot(false_positives,aes(x=r_squared,y=AIC))+
  ggplot2::geom_jitter(height=0.05,width=0.05,alpha=0.2)+
  ggplot2::geom_abline(slope=1,intercept=0,linetype=2,color="red")+
  labs(title="False Positives for ")
```

## Correlating X and Z, equal coefficients. 

Now we consider the setting where the true model is still $Y = \beta_0 + \beta_1X_1 +\beta_2X_2+ \beta_3X_3 + \beta_4X_4 + \varepsilon$, but this time there will be correlation between the $X$'s and $Z$'s. For simplicity, we will continue our assumption that $\beta_1=\beta_2=\beta_3=\beta_4$. To generate $X$ and $Z$ which are correlated, we will simulate $X_i\sim \mathcal{N}(0,1)$ and we will generate $Z_i=X_i+\mathcal{N}(0,\frac14)$:

```{r correlation between X and Z}
#setup##########################################################################
AICvectors <- list()
rsqvectors <- list()
nsim  <- 100
nsamp <- 50
beta_true <- (1/2)*c(1,1,1,1,0,0,0,0)

#simulation loop################################################################
#timing the simulation loop
start_time = Sys.time()

#for loop simulates the models and stores the shapley values
for(i in 1:nsim){
  #randomly generate explanatory covariates
  X1 <- rnorm(nsamp)
  X2 <- rnorm(nsamp)
  X3 <- rnorm(nsamp)
  X4 <- rnorm(nsamp)
  Z1 <- X1 + rnorm(nsamp,mean = 0,sd=1/4)
  Z2 <- X2 + rnorm(nsamp,mean = 0,sd=1/4)
  Z3 <- X3 + rnorm(nsamp,mean = 0,sd=1/4)
  Z4 <- X4 + rnorm(nsamp,mean = 0,sd=1/4)
  
  #put together into design matrix
  X <- cbind(X1,X2,X3,X4,Z1,Z2,Z3,Z4)
  
  #calculate Y 
  Y <- X%*%cbind(beta_true)+rnorm(nsamp)
  
  #calculate variables shapley values
  Yshap <- shapley(Y,X)
  AICvectors[[i]]<- Yshap$AIC_shapleys
  rsqvectors[[i]]<- Yshap$rsq_shapleys
}
#report time used by loop:
end_time = Sys.time()
cat("Time elapsed after ",nsim," simulations of sample size ",nsamp,":\n",
    end_time-start_time,"\n")
```

After this point, the code runs the same as before:

```{r}
#post-simulation organizing#####################################################
#store shapley values into a data frame
AICshapleys <- matrix(unlist(AICvectors),nrow=nsim,byrow=TRUE)
colnames(AICshapleys) <- names(AICvectors[[1]])
AICshapleys <- as.data.frame(AICshapleys)
AICshapleys$scorefn <- rep("AIC",nsim)
rsqshapleys <- matrix(unlist(rsqvectors),nrow=nsim,byrow=TRUE)
colnames(rsqshapleys) <- names(rsqvectors[[1]])
rsqshapleys <- as.data.frame(rsqshapleys)
rsqshapleys$scorefn <- rep("R_Squared",nsim)
shapleys <- dplyr::full_join(AICshapleys,rsqshapleys,by = c("X1", "X2", "X3", 
                                                            "X4", "Z1", "Z2", 
                                                            "Z3", "Z4", 
                                                            "scorefn"))


#Plotting histograms of shapley values##########################################
#now we transform this data frame and plot a histogram of all the shapley values
shapleys%>%
  tidyr::pivot_longer(1:8,names_to = "variable",values_to = "shapley_value")%>%
  dplyr::mutate(var_useful = grepl("X",variable))%>%
  ggplot2::ggplot(aes(x=shapley_value,fill=var_useful))+
  ggplot2::geom_histogram(position = "dodge")+
  ggplot2::facet_wrap(~scorefn,scales="free")

#calculating false positive rates###############################################
#data frame for false positives
false_positives <- data.frame(
  AIC = rep(NA,nsim),
  r_squared = rep(NA,nsim)
)

#for loop for AIC false positives
for(i in 1:nsim){
  smallest_X <- min(AICshapleys[i,1:4])
  smallest_X
  
  false_positives$AIC[i]<-sum(AICshapleys[i,5:8]>smallest_X)
  
}

#for loop for r-squared false positives
for(i in 1:nsim){
  smallest_X <- min(rsqshapleys[i,1:4])
  false_positives$r_squared[i]<-sum(rsqshapleys[i,5:8]>smallest_X)
}

#summarize these two false-positive rates
cat("False Positive summary statistics\n")
apply(false_positives,MARGIN = 2,FUN=summary)

#Separation Ratios##############################################################
separation <- data.frame(
  AIC = rep(NA,nsim),
  r_squared = rep(NA,nsim)
)

#for loop for AIC false positives
for(i in 1:nsim){
  smallest_X <- min(AICshapleys[i,1:4])
  largest_Z  <- max(AICshapleys[i,5:8])
  smallest   <- min(AICshapleys[i,1:8])
  largest    <- max(AICshapleys[i,1:8])
  separation$AIC[i]<- (smallest_X-largest_Z)/(largest-smallest)
}

#for loop for r-squared false positives
for(i in 1:nsim){
  smallest_X <- min(rsqshapleys[i,1:4])
  largest_Z  <- max(rsqshapleys[i,5:8])
  smallest   <- min(rsqshapleys[i,1:8])
  largest    <- max(rsqshapleys[i,1:8])
  separation$r_squared [i]<- (smallest_X-largest_Z)/(largest-smallest)
}

#summarize these two false-positive rates
cat("Separation ratio summary statistics\n")
apply(separation,MARGIN = 2,FUN=summary)

#plot false positives for both schemes
ggplot2::ggplot(false_positives,aes(x=r_squared,y=AIC))+
  ggplot2::geom_jitter(height=0.05,width=0.05,alpha=0.2)+
  ggplot2::geom_abline(slope=1,intercept=0,linetype=2,color="red")+
  labs(title="False Positives for ")

#plot these separation ratios, along with a y=x reference line to see when 
#AIC shapley values achieve "Better separation"
plot(separation$r_squared,separation$AIC,
     xlab="R-Squared based separation",
     ylab="AIC based separation",
     main="Separation ratios using two shapley value scoring schemes")
abline(a=0,b=1,lty=2,col="red")
```

We see that in the case where there is 
